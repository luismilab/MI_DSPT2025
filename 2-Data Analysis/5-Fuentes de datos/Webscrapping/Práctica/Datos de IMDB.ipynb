{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpS8k_tshonl"
   },
   "source": [
    "## Web scrapping de IMDB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga la información correspondiente y guarda en un dataframe el top de las 250 películas mediante webscrapping. La dirección es https://www.imdb.com/chart/top/?ref_=nv_mv_250\n",
    "\n",
    "Obtén:\n",
    "* Título\n",
    "* Año\n",
    "* Duración\n",
    "* Posición\n",
    "* Rating\n",
    "\n",
    "A veces las páginas web se protegen de las arañas con lo que deberéis simular ser un usuario... podéis instalar\n",
    "\n",
    "`!pip install fake-useragent`\n",
    "\n",
    "Y luego invocar\n",
    "\n",
    "```py\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/161.7 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/161.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 92.2/161.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 153.6/161.7 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 161.7/161.7 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "# from splinter import Browser\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "response = requests.get(url, headers= headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 25 elementos de películas.\n",
      "\n",
      "--- DataFrame de Películas ---\n",
      "  Posición                 Título   Año Duración Rating\n",
      "0        1        Cadena perpetua  1994   2h 22m    9,3\n",
      "1        2             El padrino  1972   2h 55m    9,2\n",
      "2        3    El caballero oscuro  2008   2h 32m    9,0\n",
      "3        4    El padrino parte II  1974   3h 22m    9,0\n",
      "4        5  12 hombres sin piedad  1957   1h 36m    9,0\n",
      "\n",
      "Se extrajeron 25 películas.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re # Importamos el módulo de expresiones regulares\n",
    "\n",
    "def scrape_imdb_top_250():\n",
    "    \"\"\"\n",
    "    Extrae información de las 250 mejores películas de IMDb y la devuelve en un DataFrame de Pandas.\n",
    "    \"\"\"\n",
    "    url = \"https://www.imdb.com/es-es/chart/top/?ref_=nv_mv_250\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"es-ES,es;q=0.9,en;q=0.8\" # Solicitamos la página en español\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status() # Lanza un error para respuestas HTTP malas (4xx o 5xx)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al obtener la página: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    titulos = []\n",
    "    anos = []\n",
    "    duraciones = []\n",
    "    posiciones = []\n",
    "    ratings = []\n",
    "\n",
    "    # IMDb envuelve la lista de películas en un contenedor.\n",
    "    # Basándonos en la estructura de IMDb, buscamos los elementos 'li' que representan cada película.\n",
    "    # La estructura exacta puede cambiar, así que es importante inspeccionar la página si el script falla.\n",
    "    # Por el HTML que proporcionaste, parece que cada película está en un div con una clase específica,\n",
    "    # que a su vez está dentro de elementos 'li' o directamente en un contenedor principal.\n",
    "    # Vamos a buscar los contenedores de cada película.\n",
    "    # El HTML proporcionado sugiere que cada película está en un <div class=\"sc-995e3276-1 jziSZL cli-parent li-compact\">\n",
    "    # Sin embargo, la lista principal suele estar en <ul> o <ol> o un div con un data-testid específico.\n",
    "    # Busquemos la lista que parece ser la principal:\n",
    "    movie_list_container = soup.find('ul', class_=['ipc-metadata-list', 'ipc-metadata-list--dividers-between', 'sc-71ed9118-0', 'grmHsY', 'compact-list-view', 'ipc-metadata-list--base'])\n",
    "    \n",
    "    if not movie_list_container:\n",
    "        # Intento alternativo si la clase anterior no se encuentra (IMDb actualiza sus clases a veces)\n",
    "        # El selector que has proporcionado es <div class=\"sc-995e3276-1 jziSZL cli-parent li-compact\">\n",
    "        # Estos elementos 'li' o 'div' suelen estar dentro de un contenedor mayor.\n",
    "        # Si el anterior no funciona, intentamos encontrar todos los elementos que parecen ser una película individual.\n",
    "        # Asumimos que la clase 'cli-parent' es un buen indicador.\n",
    "        movie_elements = soup.select('li .cli-parent') # Buscamos 'cli-parent' dentro de un 'li'\n",
    "        if not movie_elements: # Si no hay 'li .cli-parent', buscamos directamente 'cli-parent'\n",
    "             movie_elements = soup.find_all('div', class_=re.compile(r'cli-parent'))\n",
    "\n",
    "\n",
    "    else:\n",
    "        movie_elements = movie_list_container.find_all('li', class_=re.compile(r'ipc-metadata-list-summary-item'))\n",
    "\n",
    "\n",
    "    if not movie_elements:\n",
    "        print(\"No se pudieron encontrar los elementos de las películas. La estructura de la página puede haber cambiado.\")\n",
    "        print(\"Por favor, revisa el HTML de la página https://www.imdb.com/es-es/chart/top/ y ajusta los selectores de BeautifulSoup.\")\n",
    "        # Imprimir una porción del HTML para ayudar a depurar si es necesario (opcional)\n",
    "        # print(soup.prettify()[:2000])\n",
    "        return None\n",
    "\n",
    "    print(f\"Se encontraron {len(movie_elements)} elementos de películas.\")\n",
    "\n",
    "    for movie_el in movie_elements:\n",
    "        try:\n",
    "            # --- Título y Posición ---\n",
    "            # <h3 class=\"ipc-title__text\">1. Cadena perpetua</h3>\n",
    "            title_tag = movie_el.find('h3', class_='ipc-title__text')\n",
    "            if title_tag:\n",
    "                title_text = title_tag.get_text(strip=True)\n",
    "                # Usar regex para separar posición y título\n",
    "                match = re.match(r'(\\d+)\\.\\s*(.+)', title_text)\n",
    "                if match:\n",
    "                    posicion = match.group(1)\n",
    "                    titulo = match.group(2)\n",
    "                else:\n",
    "                    # Si no hay número, podría ser un formato diferente o no ser una película de la lista principal\n",
    "                    titulo = title_text\n",
    "                    posicion = \"N/A\" # O intentar obtenerlo de otra forma\n",
    "            else:\n",
    "                titulo = \"N/A\"\n",
    "                posicion = \"N/A\"\n",
    "\n",
    "            # --- Año, Duración ---\n",
    "            # <div class=\"sc-4b408797-7 fUdAcX cli-title-metadata\">\n",
    "            #   <span class=\"sc-4b408797-8 iurwGb cli-title-metadata-item\">1994</span>\n",
    "            #   <span class=\"sc-4b408797-8 iurwGb cli-title-metadata-item\">2h 22m</span>\n",
    "            #   <span class=\"sc-4b408797-8 iurwGb cli-title-metadata-item\">13</span>\n",
    "            # </div>\n",
    "            metadata_items = movie_el.find_all('span', class_='cli-title-metadata-item')\n",
    "            if len(metadata_items) >= 2:\n",
    "                ano = metadata_items[0].get_text(strip=True)\n",
    "                duracion = metadata_items[1].get_text(strip=True)\n",
    "                # El tercer elemento suele ser la clasificación por edad, que no pediste.\n",
    "            else:\n",
    "                ano = \"N/A\"\n",
    "                duracion = \"N/A\"\n",
    "\n",
    "            # --- Rating ---\n",
    "            # <span aria-label=\"Calificación de IMDb: 9,3\" class=\"ipc-rating-star ...\"><span class=\"ipc-rating-star--rating\">9,3</span>...</span>\n",
    "            # O directamente buscar por la clase del span interno que contiene la calificación\n",
    "            rating_tag = movie_el.find('span', class_='ipc-rating-star--rating')\n",
    "            if rating_tag:\n",
    "                rating = rating_tag.get_text(strip=True)\n",
    "            else:\n",
    "                # Intento alternativo con la estructura que diste originalmente\n",
    "                rating_container = movie_el.find('div', class_='sc-bfa1b6a1-0') # o la clase más específica 'ezSnho'\n",
    "                if rating_container:\n",
    "                    rating_value_tag = rating_container.find('span', class_='ipc-rating-star--rating')\n",
    "                    if rating_value_tag:\n",
    "                         rating = rating_value_tag.get_text(strip=True)\n",
    "                    else:\n",
    "                        rating = \"N/A\"\n",
    "                else:\n",
    "                    rating = \"N/A\"\n",
    "            \n",
    "            # Validar que tenemos datos antes de añadir (evitar filas vacías si algo falla)\n",
    "            if titulo != \"N/A\" and posicion != \"N/A\":\n",
    "                titulos.append(titulo)\n",
    "                posiciones.append(posicion)\n",
    "                anos.append(ano)\n",
    "                duraciones.append(duracion)\n",
    "                ratings.append(rating)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando una película: {e}\")\n",
    "            # Puedes decidir si añadir N/A o saltar este elemento\n",
    "            # titulos.append(\"Error\")\n",
    "            # ... y así para los demás campos\n",
    "\n",
    "    if not titulos:\n",
    "        print(\"No se pudo extraer ninguna información de las películas.\")\n",
    "        return None\n",
    "\n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Posición': posiciones,\n",
    "        'Título': titulos,\n",
    "        'Año': anos,\n",
    "        'Duración': duraciones,\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_peliculas = scrape_imdb_top_250()\n",
    "    if df_peliculas is not None:\n",
    "        print(\"\\n--- DataFrame de Películas ---\")\n",
    "        print(df_peliculas.head()) # Muestra las primeras 5 películas\n",
    "        print(f\"\\nSe extrajeron {len(df_peliculas)} películas.\")\n",
    "\n",
    "        # Para ver todas las películas:\n",
    "        # print(df_peliculas)\n",
    "\n",
    "        # Para guardar en un CSV (opcional):\n",
    "        # df_peliculas.to_csv('imdb_top_250.csv', index=False)\n",
    "        # print(\"\\nDataFrame guardado en imdb_top_250.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-DataAccess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3119",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
